{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljw8dn3WuF0r"
   },
   "source": [
    "# Hands on Machine Learning (ML) for Materials\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/paolodeangelis/AEM/blob/main/2_Hands_on_ML_for_Materials.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rPcM7-eWuF0w"
   },
   "source": [
    "# NN Model Regressor\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this hands-on tutorial, we will explore how to **predict the elastic properties** of crystalline materials using a machine learning approach. Specifically, we will show how to:\n",
    "\n",
    "1. Load a dataset of structures and their associated elastic tensors.\n",
    "2. Clean and preprocess the data (removing outliers, normalizing target values, etc.).\n",
    "3. Represent each structure with a **SOAP** (Smooth Overlap of Atomic Positions) descriptor.\n",
    "4. Train a simple **neural network** model in **PyTorch** to predict the diagonal components of the elastic tensor ($\\mathrm{C}_{11}, \\mathrm{C}_{22}, \\mathrm{C}_{33}, \\mathrm{C}_{44}, \\mathrm{C}_{55}, \\mathrm{C}_{66}$).\n",
    "5. Evaluate model performance using metrics such as **mean absolute error** (MAE) and **$R^2$**.\n",
    "6. [Optional] Compare these predictions with a direct **DFT-based approach** (via MACE) for calculating certain elastic constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUpjaxVssoO_"
   },
   "source": [
    "## Theoretical Context\n",
    "\n",
    "### Elastic Tensor\n",
    "\n",
    "A second-order elastic stiffness tensor $\\mathbf{C}$ in 3D has 36 components, which are typically reduced to 21 independent components by symmetry. It generalizes **Hooke's law** and **completely** describes the elastic **behavior** of the material.\n",
    "\n",
    "$$\n",
    "    \\begin{pmatrix}\n",
    "    \\sigma_{11}\\\\[6pt]\n",
    "    \\sigma_{22}\\\\[6pt]\n",
    "    \\sigma_{33}\\\\[6pt]\n",
    "    \\sigma_{23}\\\\[6pt]\n",
    "    \\sigma_{13}\\\\[6pt]\n",
    "    \\sigma_{12}\n",
    "    \\end{pmatrix}\n",
    "    =\n",
    "    \\underbrace{\\begin{pmatrix}\n",
    "    C_{11} & C_{12} & C_{13} & C_{14} & C_{15} & C_{16}\\\\[6pt]\n",
    "    C_{21} & C_{22} & C_{23} & C_{24} & C_{25} & C_{26}\\\\[6pt]\n",
    "    C_{31} & C_{32} & C_{33} & C_{34} & C_{35} & C_{36}\\\\[6pt]\n",
    "    C_{41} & C_{42} & C_{43} & C_{44} & C_{45} & C_{46}\\\\[6pt]\n",
    "    C_{51} & C_{52} & C_{53} & C_{54} & C_{55} & C_{56}\\\\[6pt]\n",
    "    C_{61} & C_{62} & C_{63} & C_{64} & C_{65} & C_{66}\n",
    "    \\end{pmatrix}}_{\\displaystyle \\text{(6×6 stiffness matrix)}}\n",
    "    \\begin{pmatrix}\n",
    "    \\varepsilon_{11}\\\\[6pt]\n",
    "    \\varepsilon_{22}\\\\[6pt]\n",
    "    \\varepsilon_{33}\\\\[6pt]\n",
    "    2\\,\\varepsilon_{23}\\\\[6pt]\n",
    "    2\\,\\varepsilon_{13}\\\\[6pt]\n",
    "    2\\,\\varepsilon_{12}\n",
    "    \\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "Here we focus on the diagonal components:\n",
    "\n",
    "$$\n",
    "C_{11}, \\quad C_{22}, \\quad C_{33}, \\quad C_{44}, \\quad C_{55}, \\quad C_{66}.\n",
    "$$\n",
    "\n",
    "In the most common engineering notation, the linear relation between stress $\\sigma$ and strain $\\varepsilon$ can be written as:\n",
    "\n",
    "$$\n",
    "\\sigma_{ij} = \\sum_{k, l} C_{ijkl} \\,\\varepsilon_{kl},\n",
    "$$\n",
    "\n",
    "where $\\sigma_{ij}$ is the stress tensor, $\\varepsilon_{kl}$ is the strain tensor, and $C_{ijkl}$ are the elastic stiffness constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bB1Z1lyDyE18"
   },
   "source": [
    "## [Step 1]: Install library and download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hiquS3tdAtIk",
    "outputId": "54065e75-bc29-43d3-dea8-7c26c5da3a52"
   },
   "outputs": [],
   "source": [
    "%pip install torch torchvision pandas matplotlib numpy pymatgen dscribe scikit-learn tqdm mp-api pandas iterative-stratification mace-torch nglview "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzSjrLJ0AugJ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ase import Atoms\n",
    "from dscribe.descriptors import SOAP\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "from pymatgen.core import Composition, Structure\n",
    "from scipy.stats import zscore\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note**: The following setting must be changed in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pMDf8eEHSoNu"
   },
   "outputs": [],
   "source": [
    "N_SAMPLES = 5000  # Number of samples to use\n",
    "SEED = 42  # Random seed to ensure reproducibility\n",
    "BATCH_SIZE = 8  # Batch size\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.set_default_dtype(torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dowload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/paolodeangelis/AEM/raw/refs/heads/main/data/elasticity_full_properties.h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "px-MEs6hSpkF"
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_hdf(\"elasticity_full_properties.h5\", key=\"df\")\n",
    "\n",
    "df_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 2]: Data cleaning & Downsampling\n",
    "\n",
    "**Data Cleaning Steps**:\n",
    "\n",
    "1. **Drop missing data** in `\"Structure\"` or `\"Elastic Tensor\"`.  \n",
    "2. **Extract diagonal components** $(C_{11}, C_{22}, \\ldots, C_{66})$ from the elastic tensor.  \n",
    "3. **Remove outliers** using the IQR method, filtering extreme values in each diagonal component.  \n",
    "4. **Shuffle** the remaining dataset randomly.  \n",
    "5. **Select** only the first `N_SAMPLES` rows for practical training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop missing data\n",
    "df_full = df_full.dropna(subset=[\"Structure\", \"Elastic Tensor\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hnX1LDxYDUzv"
   },
   "outputs": [],
   "source": [
    "# Extract targets\n",
    "tensor_components = [\"C11\", \"C22\", \"C33\", \"C44\", \"C55\", \"C66\"]\n",
    "tensor_indices = [(0, 0), (1, 1), (2, 2), (3, 3), (4, 4), (5, 5)]\n",
    "\n",
    "for i, (r, c) in enumerate(tensor_indices):\n",
    "    df_full[tensor_components[i]] = df_full[\"Elastic Tensor\"].apply(\n",
    "        lambda x: np.array(x)[r, c]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6I1qgI2RnHh"
   },
   "outputs": [],
   "source": [
    "# IQR-based outlier removal for each tensor component\n",
    "\n",
    "\n",
    "def remove_outliers_iqr(df, cols):\n",
    "    df_clean = df.copy()\n",
    "    for col in cols:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        df_clean = df_clean[\n",
    "            (df_clean[col] >= lower_bound) & (df_clean[col] <= upper_bound)\n",
    "        ]\n",
    "    return df_clean.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6aHZkr7pTBPP"
   },
   "outputs": [],
   "source": [
    "df_clean = remove_outliers_iqr(df_full, tensor_components)\n",
    "print(f\"Removed {len(df_full)-len(df_clean)} outliers. Remaining data: {len(df_clean)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z1n4vj4bS-sB",
    "outputId": "59ed7ff2-2de6-4aca-ebfe-231e205bce4d"
   },
   "source": [
    "Downsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k368GvcsTEQf",
    "outputId": "54ea5fa6-f541-4c43-9aa5-8d9ab825e568"
   },
   "outputs": [],
   "source": [
    "df_clean_shuffled = df_clean.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "\n",
    "# Select only first N_SAMPLES\n",
    "df_final = df_clean_shuffled.iloc[:N_SAMPLES].reset_index(drop=True)\n",
    "print(f\"Final dataset size: {len(df_final)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFpOfOGwre2s"
   },
   "source": [
    "## [Step 3]: Data Splitting \n",
    "\n",
    "Instead of a purely random split, we perform a **multilabel stratified split** based on the presence or absence of each chemical element in the structures. Here's why:\n",
    "\n",
    "1. **Element Distribution**: A simple random split may result in some elements being over-represented in either the training or test set (or missing entirely in one of them).  \n",
    "2. **Balanced Training**: By using a stratified approach, we ensure that each element’s frequency distribution is maintained across both sets, giving the model a more representative range of materials during training and an unbiased evaluation on the test set.  \n",
    "3. **Improved Robustness**: Preserving distribution across all labels (elements) reduces the risk of skewing the model toward certain compositions and thus generally improves its predictive robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U18L6914t9WJ",
    "outputId": "0b65df1e-fd48-4ea3-d4ba-6ce2c83989af"
   },
   "outputs": [],
   "source": [
    "# Step 1: Get all unique elements\n",
    "all_elements = sorted(\n",
    "    {str(el) for s in df_final[\"Structure\"] for el in s.composition.elements}\n",
    ")\n",
    "element_to_idx = {el: i for i, el in enumerate(all_elements)}\n",
    "\n",
    "# Step 2: Build binary matrix (samples × elements)\n",
    "binary_matrix = np.zeros((len(df_final), len(all_elements)), dtype=int)\n",
    "\n",
    "for i, s in enumerate(df_final[\"Structure\"]):\n",
    "    comp = s.composition\n",
    "    for el in comp:\n",
    "        binary_matrix[i, element_to_idx[str(el)]] = 1\n",
    "\n",
    "# Step 3: Stratified multilabel split (preserves element distributions)\n",
    "sss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=SEED)\n",
    "train_idx, test_idx = next(sss.split(df_final, binary_matrix))\n",
    "\n",
    "print(f\"Train size: {len(train_idx)}, Test size: {len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "id": "G7Y0sS14uQjC",
    "outputId": "d7f7ae95-6efc-465c-93a8-ce18ea82ef5f"
   },
   "outputs": [],
   "source": [
    "def get_element_distribution(indices):\n",
    "    counter = {el: 0 for el in all_elements}\n",
    "    for s in df_final.iloc[indices][\"Structure\"]:\n",
    "        comp = s.composition\n",
    "        for el in comp:\n",
    "            counter[str(el)] += comp[el]\n",
    "    total = sum(counter.values())\n",
    "    return {el: counter[el] / total for el in counter}\n",
    "\n",
    "\n",
    "train_dist = get_element_distribution(train_idx)\n",
    "test_dist = get_element_distribution(test_idx)\n",
    "\n",
    "# Plot comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "x = np.arange(len(all_elements))\n",
    "train_vals = [train_dist[el] for el in all_elements]\n",
    "test_vals = [test_dist[el] for el in all_elements]\n",
    "\n",
    "plt.bar(x - 0.2, train_vals, width=0.4, label=\"Train\")\n",
    "plt.bar(x + 0.2, test_vals, width=0.4, label=\"Test\")\n",
    "plt.xticks(x, all_elements, rotation=90)\n",
    "plt.ylabel(\"Normalized Frequency\")\n",
    "plt.title(\"Element Frequency Distribution: Train vs Test\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ElasticSOAPDataset`: On-the-Fly Feature Extraction\n",
    "\n",
    "The **`ElasticSOAPDataset`** class is a custom **PyTorch** dataset designed to:\n",
    "1. **Store the raw data** (each row’s `Structure` and corresponding target properties).\n",
    "2. **Generate SOAP descriptors** for each structure **on the fly**.\n",
    "\n",
    "Why generate features on the fly?\n",
    "- **Memory Efficiency**: Storing all SOAP vectors for large datasets can be highly memory-intensive. Creating them on demand avoids holding massive arrays in memory.  \n",
    "- **Flexibility**: If you wish to alter descriptor parameters (e.g., `r_cut`, `n_max`, `l_max`), the dataset can dynamically re-calculate descriptors without needing to rewrite the entire feature set.  \n",
    "- **Seamless Integration**: PyTorch’s **`DataLoader`** works seamlessly with datasets that compute features when needed (in each training batch), supporting parallel or background loading if desired.\n",
    "\n",
    "Overall, this approach keeps the pipeline **modular**, **efficient**, and **easy to maintain**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ElasticSOAPDataset(Dataset):\n",
    "    def __init__(self, dataframe, soap_params):\n",
    "        self.df = dataframe\n",
    "        self.soap = SOAP(**soap_params)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        structure = self.df.loc[idx, \"Structure\"]\n",
    "\n",
    "        ase_structure = Atoms(\n",
    "            symbols=[str(s.specie) for s in structure],\n",
    "            positions=structure.cart_coords,\n",
    "            cell=structure.lattice.matrix,\n",
    "            pbc=True,\n",
    "        )\n",
    "\n",
    "        feature = self.soap.create(ase_structure, n_jobs=1).flatten()\n",
    "\n",
    "        target = self.df.loc[\n",
    "            idx, [\"C11\", \"C22\", \"C33\", \"C44\", \"C55\", \"C66\"]\n",
    "        ].values.astype(float)\n",
    "\n",
    "        return torch.tensor(feature, dtype=torch.float32), torch.tensor(\n",
    "            target, dtype=torch.float32\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M7LfqRTUDI5c"
   },
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# indices = np.arange(len(df_final))\n",
    "# train_idx, test_idx = train_test_split(indices, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "species = list({str(el) for s in df_final[\"Structure\"] for el in s.species})\n",
    "\n",
    "soap_params = {\n",
    "    \"species\": species,\n",
    "    \"periodic\": True,\n",
    "    \"r_cut\": 6.0,\n",
    "    \"n_max\": 5,\n",
    "    \"l_max\": 2,\n",
    "    \"average\": \"inner\",\n",
    "}\n",
    "\n",
    "train_dataset = ElasticSOAPDataset(\n",
    "    df_final.iloc[train_idx].reset_index(drop=True), soap_params\n",
    ")\n",
    "test_dataset = ElasticSOAPDataset(\n",
    "    df_final.iloc[test_idx].reset_index(drop=True), soap_params\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Periodic Table with element couting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 587
    },
    "id": "Q5vMhde4tZnn",
    "outputId": "3f60ad3a-0cc6-4ab6-dfc2-4d13b2247649"
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors  # Import colors for LogNorm and explicit colors\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pymatgen.core import Composition, Lattice, Structure\n",
    "from pymatgen.core.periodic_table import Element, get_el_sp\n",
    "\n",
    "# 1. Count element frequencies\n",
    "element_counts = {}\n",
    "try:\n",
    "    for s in df_final.iloc[train_idx][\"Structure\"]:\n",
    "        comp = s.composition\n",
    "        for el_sym in comp.keys():  # Use element symbol object from composition\n",
    "            element = Element(el_sym.symbol)  # Get pymatgen Element from symbol string\n",
    "            element_counts[element] = element_counts.get(element, 0) + comp[el_sym]\n",
    "except Exception as e:\n",
    "    print(f\"Error processing structures: {e}. Check df_final format.\")\n",
    "    element_counts = {Element(\"H\"): 1, Element(\"O\"): 2}  # Minimal fallback data\n",
    "\n",
    "# 2. Normalize frequencies\n",
    "total_atoms = sum(element_counts.values())\n",
    "element_freq = {}\n",
    "if total_atoms > 0:\n",
    "    # element_freq = {el: count / total_atoms for el, count in element_counts.items()}\n",
    "    element_freq = {el: count for el, count in element_counts.items()}\n",
    "else:\n",
    "    print(\"Warning: No atoms found in the dataset.\")\n",
    "\n",
    "# --- Plotting Setup ---\n",
    "MAX_Z = 103  # Define the maximum atomic number to display (e.g., up to Lr)\n",
    "MISSING_FACE_COLOR = \"lightgrey\"\n",
    "MISSING_TEXT_COLOR = \"dimgray\"\n",
    "PRESENT_EDGE_COLOR = \"gray\"\n",
    "\n",
    "# 3. Prepare Colormap and Normalization for PRESENT elements\n",
    "cmap = plt.get_cmap(\"viridis\")\n",
    "norm = None\n",
    "min_freq = 1.0\n",
    "max_freq = 0.0\n",
    "\n",
    "if element_freq:\n",
    "    present_frequencies = [freq for freq in element_freq.values() if freq > 0]\n",
    "    if present_frequencies:\n",
    "        min_freq = min(present_frequencies)\n",
    "        max_freq = max(present_frequencies)\n",
    "        # Use LogNorm - ensure vmin is positive and slightly less than actual min\n",
    "        norm = mcolors.LogNorm(\n",
    "            vmin=min_freq * 0.9 if min_freq > 0 else 1e-9, vmax=max_freq\n",
    "        )\n",
    "    else:\n",
    "        print(\"Warning: All element frequencies are zero.\")\n",
    "else:\n",
    "    print(\"Warning: No element frequencies calculated.\")\n",
    "\n",
    "\n",
    "# 4. Helper function for element coordinates (includes Ln/Ac placement)\n",
    "def get_element_display_coords(element: Element):\n",
    "    \"\"\"Calculates display row and group for standard periodic table layout.\"\"\"\n",
    "    row = element.row\n",
    "    group = element.group\n",
    "\n",
    "    if 57 <= element.Z <= 71:  # Lanthanides (La-Lu) -> display row 9\n",
    "        display_row = 9\n",
    "        display_group = 3 + (\n",
    "            element.Z - 57\n",
    "        )  # Place sequentially starting in group 3 column space\n",
    "    elif 89 <= element.Z <= 103:  # Actinides (Ac-Lr) -> display row 10\n",
    "        display_row = 10\n",
    "        display_group = 3 + (\n",
    "            element.Z - 89\n",
    "        )  # Place sequentially starting in group 3 column space\n",
    "    else:\n",
    "        display_row = row\n",
    "        display_group = group\n",
    "\n",
    "    return display_row, display_group\n",
    "\n",
    "\n",
    "# 5. Plotting\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "ax.set_aspect(\"equal\")\n",
    "\n",
    "# Determine max plot dimensions based on MAX_Z elements' positions\n",
    "max_disp_row = 0\n",
    "max_disp_group = 0\n",
    "all_coords = {}\n",
    "for Z in range(1, MAX_Z + 1):\n",
    "    try:\n",
    "        element = Element.from_Z(Z)\n",
    "        disp_r, disp_g = get_element_display_coords(element)\n",
    "        all_coords[Z] = (disp_r, disp_g, element.symbol)\n",
    "        max_disp_row = max(max_disp_row, disp_r)\n",
    "        max_disp_group = max(max_disp_group, disp_g)\n",
    "    except ValueError:\n",
    "        print(f\"Warning: Could not get Element object for Z={Z}\")\n",
    "        continue  # Skip if pymatgen doesn't know the element\n",
    "\n",
    "ax.set_xlim(0, max_disp_group + 1)\n",
    "ax.set_ylim(max_disp_row + 1, 0)  # Set limits *before* inverting y-axis\n",
    "# ax.invert_yaxis()  # Ensure row 1 is at the top\n",
    "\n",
    "\n",
    "# --- Iterate through ALL elements up to MAX_Z ---\n",
    "for Z in range(1, MAX_Z + 1):\n",
    "    if Z not in all_coords:\n",
    "        continue  # Skip if coordinates weren't determined\n",
    "\n",
    "    disp_r, disp_g, symbol = all_coords[Z]\n",
    "    element_obj = Element(symbol)  # Get Element object for checking frequency dict\n",
    "\n",
    "    face_color = MISSING_FACE_COLOR\n",
    "    text_color = MISSING_TEXT_COLOR\n",
    "    edge_color = \"silver\"  # Lighter edge for missing elements\n",
    "    label = symbol  # Default label is just the symbol\n",
    "\n",
    "    # Check if this element is in our frequency data\n",
    "    if element_obj in element_freq and element_freq[element_obj] > 0 and norm:\n",
    "        freq_val = element_freq[element_obj]\n",
    "        face_color = cmap(norm(freq_val))\n",
    "        edge_color = PRESENT_EDGE_COLOR\n",
    "\n",
    "        # Determine text color based on background luminance\n",
    "        luminance = (\n",
    "            0.2126 * face_color[0] + 0.7152 * face_color[1] + 0.0722 * face_color[2]\n",
    "        )\n",
    "        text_color = \"white\" if luminance < 0.5 else \"black\"\n",
    "        # Optional: add frequency to label for present elements\n",
    "        # label = f\"{symbol}\\n{freq_val:.2e}\" # Show frequency in scientific notation\n",
    "\n",
    "    # Draw the rectangle (element cell)\n",
    "    rect = patches.Rectangle(\n",
    "        (disp_g - 0.5, disp_r - 0.5),\n",
    "        1,\n",
    "        1,\n",
    "        linewidth=0.5,\n",
    "        edgecolor=edge_color,\n",
    "        facecolor=face_color,\n",
    "    )\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    # Add element symbol (or label)\n",
    "    ax.text(\n",
    "        disp_g,\n",
    "        disp_r,\n",
    "        label,\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        fontsize=9,\n",
    "        weight=\"bold\" if face_color != MISSING_FACE_COLOR else \"normal\",\n",
    "        color=text_color,\n",
    "    )\n",
    "\n",
    "# --- Add Group/Row Labels (Optional but Recommended) ---\n",
    "# Group numbers (columns 1-18)\n",
    "for i in range(1, max_disp_group + 1):\n",
    "    # Find the minimum display row for any element in this group (main block or Ln/Ac)\n",
    "    min_row_in_group = float(\"inf\")\n",
    "    has_element_in_group = False\n",
    "    for r, g, _ in all_coords.values():\n",
    "        if g == i:\n",
    "            min_row_in_group = min(min_row_in_group, r)\n",
    "            has_element_in_group = True\n",
    "\n",
    "    if has_element_in_group:\n",
    "        # Place label above the highest element in that column\n",
    "        ax.text(\n",
    "            i,\n",
    "            min_row_in_group - 0.8,\n",
    "            str(i),\n",
    "            ha=\"center\",\n",
    "            va=\"bottom\",\n",
    "            fontsize=9,\n",
    "            color=\"gray\",\n",
    "        )\n",
    "\n",
    "# Row numbers (periods 1-7, plus Ln/Ac labels)\n",
    "for i in range(1, max_disp_row + 1):\n",
    "    # Find the minimum display group for any element in this row\n",
    "    min_group_in_row = float(\"inf\")\n",
    "    has_element_in_row = False\n",
    "    label = str(i)  # Default label is row number\n",
    "    if i == 9:\n",
    "        label = \"Ln\"\n",
    "    if i == 10:\n",
    "        label = \"Ac\"\n",
    "\n",
    "    for r, g, _ in all_coords.values():\n",
    "        if r == i:\n",
    "            min_group_in_row = min(min_group_in_row, g)\n",
    "            has_element_in_row = True\n",
    "\n",
    "    if has_element_in_row:\n",
    "        # Place label left of the first element in that row\n",
    "        ax.text(\n",
    "            min_group_in_row - 0.8,\n",
    "            i,\n",
    "            label,\n",
    "            ha=\"right\",\n",
    "            va=\"center\",\n",
    "            fontsize=9,\n",
    "            color=\"gray\",\n",
    "        )\n",
    "\n",
    "\n",
    "# --- Final Aesthetics ---\n",
    "# ax.invert_yaxis() # Ensure row 1 is at the top *AFTER* setting limits and plotting\n",
    "plt.title(f\"Element Frequency in Training Set (Z=1-{MAX_Z}, Log Scale)\")\n",
    "plt.axis(\"off\")  # Turn off the outer axis border and ticks\n",
    "\n",
    "# Add color bar *only* if there were present elements to normalize\n",
    "if norm:\n",
    "    sm = plt.cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "    sm.set_array([])  # Required empty array\n",
    "    cbar = plt.colorbar(sm, ax=ax, shrink=0.7, aspect=20, pad=0.03)\n",
    "    cbar.set_label(\"Relative Element Frequency (Log Scale)\")\n",
    "else:\n",
    "    # Optional: Add a note if no frequency data is shown\n",
    "    ax.text(\n",
    "        0.5,\n",
    "        -0.05,\n",
    "        \"No frequency data to display.\",\n",
    "        transform=ax.transAxes,\n",
    "        ha=\"center\",\n",
    "        fontsize=10,\n",
    "        color=\"red\",\n",
    "    )\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 4]: Model Definition and Training\n",
    "\n",
    "### Network Architecture\n",
    "\n",
    "The `ElasticSOAPNet` class defines a simple **fully connected** neural network to predict six diagonal components $\\bigl(C_{11}, C_{22}, \\ldots, C_{66}\\bigr)$. Its key layers are:\n",
    "- An **input layer** matching the dimensionality of the SOAP descriptor.\n",
    "- Hidden layers of size 128, 32, and 16, each followed by a **ReLU** activation and **dropout** for regularization.\n",
    "- An **output layer** producing 6 predicted elastic constants.\n",
    "\n",
    "```python\n",
    "class ElasticSOAPNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=6):\n",
    "        super(ElasticSOAPNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "```\n",
    "\n",
    "### Loss Function\n",
    "\n",
    "We train the model to minimize the **Mean Squared Error (MSE)** between the predicted ($\\hat{\\mathbf{y}}_i$) and actual ($\\mathbf{y}_i$) elastic tensor components. Formally, for $N$ training samples:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(\\boldsymbol{\\theta}) \\;=\\; \\frac{1}{N} \\sum_{i=1}^N \\|\\mathbf{y}_i - \\hat{\\mathbf{y}}_i(\\boldsymbol{\\theta})\\|^2,\n",
    "$$\n",
    "\n",
    "where $\\boldsymbol{\\theta}$ represents all learnable parameters in the network.\n",
    "\n",
    "### Training Procedure\n",
    "\n",
    "1. **Model Initialization**  \n",
    "   - Instantiate `ElasticSOAPNet` with the input dimension equal to the SOAP descriptor size and `output_dim=6`.\n",
    "\n",
    "2. **Optimizer**  \n",
    "   - We use the **Adam** optimizer with a learning rate of `0.0005` and a small weight decay (`1e-4`) to help regularize the model parameters.\n",
    "\n",
    "3. **Forward Pass**  \n",
    "   - For each mini-batch, we compute predicted values $\\hat{\\mathbf{y}}_i$ by passing the SOAP features through the network.\n",
    "\n",
    "4. **Compute Loss**  \n",
    "   - Calculate MSE loss by comparing predictions to true targets for each batch.\n",
    "\n",
    "5. **Backward Pass**  \n",
    "   - Perform **backpropagation** to compute gradients with respect to all parameters.\n",
    "\n",
    "6. **Update Parameters**  \n",
    "   - The optimizer (Adam) updates each parameter based on the computed gradients.\n",
    "\n",
    "By iterating through these steps for each epoch, the network progressively **learns** to minimize the MSE loss and provide **accurate predictions** of the target elastic constants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3VMgfEJDsup"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ElasticSOAPNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=6):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),  ### <<<<<< TO CANGE\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(16, output_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8fcYGie4I0IZ",
    "outputId": "a62f714c-583d-45fe-92d2-49269975f370"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvpztchZI2vd"
   },
   "outputs": [],
   "source": [
    "sample_feature, _ = train_dataset[0]\n",
    "model = ElasticSOAPNet(input_dim=sample_feature.shape[0]).to(device)\n",
    "\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y4g_PCpiFtOE",
    "outputId": "8ebb374c-49ea-492c-9000-d622f785609b"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 5\n",
    "model.train()\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    progress = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\" batch\")\n",
    "\n",
    "    for i, (features, targets) in enumerate(progress):\n",
    "        features, targets = features.to(device), targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        avg_epoch_loss = epoch_loss / (i + 1)\n",
    "\n",
    "        progress.set_postfix(\n",
    "            batch_loss=f\"{loss.item():.4f}\", epoch_avg_loss=f\"{avg_epoch_loss:.4f}\"\n",
    "        )\n",
    "\n",
    "    avg_epoch_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_epoch_loss)\n",
    "\n",
    "    # Validation loss computation\n",
    "    model.eval()\n",
    "    val_epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for val_features, val_targets in test_loader:\n",
    "            val_features, val_targets = val_features.to(device), val_targets.to(device)\n",
    "            val_outputs = model(val_features)\n",
    "            val_loss = criterion(val_outputs, val_targets)\n",
    "            val_epoch_loss += val_loss.item()\n",
    "\n",
    "    val_epoch_loss /= len(test_loader)\n",
    "    val_losses.append(val_epoch_loss)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch [{epoch+1}/{epochs}] Train Loss: {avg_epoch_loss:.4f} | Val Loss: {val_epoch_loss:.4f}\"\n",
    "    )\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the **Learning Curves**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "fSmVlAlHT2CF",
    "outputId": "5a110ee0-c175-4bc6-f58c-1e35c948e883"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, epochs + 1), train_losses, label=\"Training Loss\", marker=\"o\")\n",
    "plt.plot(range(1, epochs + 1), val_losses, label=\"Validation Loss\", marker=\"o\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Step 5]: Model Evaluation\n",
    "\n",
    "After training, we evaluate the performance of our neural network on both the **training** and **test** sets using **MAE** (Mean Absolute Error) and the **$R^2$** coefficient of determination. Here’s how it works:\n",
    "\n",
    "1. **Gathering Predictions**  \n",
    "   - We define a helper function `get_predictions(model, loader, device)` which:\n",
    "     - Sets the model to *evaluation* mode (`model.eval()`).\n",
    "     - Iterates over the **DataLoader** batches without computing gradients (`torch.no_grad()`).\n",
    "     - Collects all predicted values and the corresponding ground truth targets.\n",
    "\n",
    "2. **Metrics**  \n",
    "   - For each diagonal component $\\mathrm{C}_{ii}$:\n",
    "     - **MAE**: Measures the average absolute difference between predicted and true values.\n",
    "       $$\n",
    "         \\mathrm{MAE} \\;=\\; \\frac{1}{N}\\sum_{i=1}^N \\bigl| y_i - \\hat{y}_i \\bigr|\n",
    "       $$\n",
    "     - **$R^2$**: A measure of how much variance in the target is explained by the model, with 1.0 being perfect:\n",
    "       $$\n",
    "         R^2 \\;=\\; 1 - \\frac{\\sum_i (y_i - \\hat{y}_i)^2}{\\sum_i (y_i - \\bar{y})^2}.\n",
    "       $$\n",
    "       Here $\\bar{y}$ is the mean of the true values.\n",
    "\n",
    "3. **Parity Plots**  \n",
    "   - We create a **scatter plot** of **Actual vs. Predicted** for each component. \n",
    "   - An **identity line** ($y=x$) helps visualize how close predictions are to the ground truth.\n",
    "   - We overlay **train** and **test** points in different colors, making it easy to compare **overfitting** (train points hugging the line but test points diverging) or good **generalization** (both sets closely match).\n",
    "\n",
    "These visual and numerical evaluations provide a clear picture of the model’s **accuracy** and **robustness** in predicting the six diagonal components of the elastic tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-zerWKlnGYj1",
    "outputId": "5935480a-7220-432c-b7c4-fe1eaf4c36b8"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, loader, device):\n",
    "    model.eval()\n",
    "    preds, actuals = [], []\n",
    "    with torch.no_grad():\n",
    "        for features, targets in tqdm(loader, desc=\"Evaluating\"):\n",
    "            features = features.to(device)\n",
    "            outputs = model(features).cpu().numpy()\n",
    "            preds.append(outputs)\n",
    "            actuals.append(targets.numpy())\n",
    "    return np.vstack(actuals), np.vstack(preds)\n",
    "\n",
    "\n",
    "# Predictions on Train and Test datasets\n",
    "train_actuals, train_preds = get_predictions(model, train_loader, device)\n",
    "test_actuals, test_preds = get_predictions(model, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 670
    },
    "id": "T3FiI4tEJ8op",
    "outputId": "fc6a7089-5c85-4e73-f0c7-cf17f68b4864"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "tensor_components = [\"C11\", \"C22\", \"C33\", \"C44\", \"C55\", \"C66\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle(\"Parity Plots: Train vs Test Overlay\", fontsize=18)\n",
    "\n",
    "for i, comp in enumerate(tensor_components):\n",
    "    # Train metrics\n",
    "    train_mae = mean_absolute_error(train_actuals[:, i], train_preds[:, i])\n",
    "    train_r2 = r2_score(train_actuals[:, i], train_preds[:, i])\n",
    "\n",
    "    # Test metrics\n",
    "    test_mae = mean_absolute_error(test_actuals[:, i], test_preds[:, i])\n",
    "    test_r2 = r2_score(test_actuals[:, i], test_preds[:, i])\n",
    "\n",
    "    ax = axes.reshape(-1)[i]\n",
    "    ax.scatter(\n",
    "        train_actuals[:, i], train_preds[:, i], alpha=0.6, label=\"Train\", color=\"blue\"\n",
    "    )\n",
    "    ax.scatter(\n",
    "        test_actuals[:, i], test_preds[:, i], alpha=0.6, label=\"Test\", color=\"orange\"\n",
    "    )\n",
    "\n",
    "    # Identity line\n",
    "    all_vals = np.concatenate(\n",
    "        [train_actuals[:, i], train_preds[:, i], test_actuals[:, i], test_preds[:, i]]\n",
    "    )\n",
    "    min_val, max_val = all_vals.min(), all_vals.max()\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], \"r--\")\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"{comp}\\nTrain MAE: {train_mae:.1f}, R²: {train_r2:.2f}\\nTest MAE: {test_mae:.1f}, R²: {test_r2:.2f}\"\n",
    "    )\n",
    "    ax.set_xlabel(\"Actual (GPa)\")\n",
    "    ax.set_ylabel(\"Predicted (GPa)\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.05, 1, 0.9])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "foCxNni9KFOt",
    "outputId": "a67f0650-2f09-49a3-fb68-3f9321fe1467"
   },
   "source": [
    "# Verification (Our model VS MACE)\n",
    "\n",
    "### Downloading and Uploading a Crystal Structure from Materials Project\n",
    "\n",
    "1. **Go to Materials Project**  \n",
    "   - Visit [materialsproject.org](https://materialsproject.org/).  \n",
    "   - If you are not already signed in, create a free account or log in.  \n",
    "\n",
    "2. **Search for \"Silicon\"**  \n",
    "   - In the search bar, type \"Silicon\" or use the chemical formula \"Si.\"  \n",
    "   - You’ll see one or more entries for stable/low-energy structures (e.g., mp-149).  \n",
    "\n",
    "3. **Download the CIF**  \n",
    "   - Open the structure entry you are interested in.  \n",
    "   - Click on the **\"Download\"** or **\"Export\"** button and select **CIF** to save the file locally (e.g., `Si.cif`).  \n",
    "\n",
    "4. **Upload to Google Colab**  \n",
    "   - In your Colab notebook interface, look on the left sidebar for the **Files** tab.  \n",
    "   - Drag and drop the downloaded `Si.cif` file into the **home folder** (or any target folder where your code can access it).  \n",
    "\n",
    "5. **Repeat for Your Assigned Structure**  \n",
    "   - For the assignment at home, follow the same steps for the structure given in your **group assignment**.  \n",
    "   - Download its CIF from Materials Project or a similar database.  \n",
    "   - Upload it into Colab (e.g., `MyStructure.cif`) so your notebook can read it.\n",
    "\n",
    "Once uploaded, you can confirm the file is there by listing the directory contents inside Colab, for example:\n",
    "```python\n",
    "!ls\n",
    "```\n",
    "\n",
    "This ensures you have the crystal structure files ready for **featurization** (SOAP, etc.) and subsequent **elastic constant predictions**.\n",
    "```axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tht9bYuiKL3O",
    "outputId": "689c2481-6d54-4d28-b4cb-409d263fee4c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from ase.io import read\n",
    "from dscribe.descriptors import SOAP\n",
    "\n",
    "FILE_NAME = \"Si.cif\"\n",
    "\n",
    "# === Load the structure ===\n",
    "atoms = read(\"Si.cif\")\n",
    "\n",
    "# === Recreate the SOAP descriptor ===\n",
    "# Assumes soap_params is already defined as before\n",
    "soap = SOAP(**soap_params)\n",
    "\n",
    "# === Create descriptor for the structure ===\n",
    "feature = soap.create(atoms, n_jobs=-1).flatten()\n",
    "feature_tensor = (\n",
    "    torch.tensor(feature, dtype=torch.float32).unsqueeze(0).to(device)\n",
    ")  # batch size = 1\n",
    "del feature\n",
    "\n",
    "# === Load the trained model ===\n",
    "# model.eval()\n",
    "\n",
    "# === Predict elastic properties ===\n",
    "with torch.no_grad():\n",
    "    prediction = model(feature_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# === Output ===\n",
    "tensor_components = [\"C11\", \"C22\", \"C33\", \"C44\", \"C55\", \"C66\"]\n",
    "print(\"Predicted elastic tensor components (GPa):\")\n",
    "for comp, value in zip(tensor_components, prediction):\n",
    "    print(f\"{comp}: {value:.2f}\")\n",
    "del feature_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using MACE to Compute the Stress Tensor and Extract Elastic Constants\n",
    "\n",
    "### Theoretical Background\n",
    "\n",
    "For a **small strain** $\\boldsymbol{\\varepsilon}$, the change in total energy $\\Delta E$ relative to the unstrained reference ($\\varepsilon = 0$) can be approximated by:\n",
    "\n",
    "$$\n",
    "\\Delta E(\\boldsymbol{\\varepsilon}) \\;=\\; \\frac{1}{2}\\, V \\, \\boldsymbol{\\varepsilon}^T \\, \\mathbf{C} \\, \\boldsymbol{\\varepsilon},\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{C}$ is the **elastic stiffness matrix** (or specific components of it),\n",
    "- $V$ is the **equilibrium volume** of the crystal,\n",
    "- $\\boldsymbol{\\varepsilon}$ is the strain vector (in Voigt notation for simplicity).\n",
    "\n",
    "Focusing on a single elastic constant $C_{ij}$, we often apply **one** independent component of strain $ \\varepsilon $ at a time to the reference cell. Then the energy change simplifies to:\n",
    "\n",
    "$$\n",
    "\\Delta E(\\varepsilon) \\;\\approx\\; \\tfrac{1}{2}\\, C_{ij}\\, V\\, \\varepsilon^2.\n",
    "$$\n",
    "\n",
    "By **polynomial-fitting** $\\Delta E$ vs. $\\varepsilon^2$ over small strains (e.g., $\\varepsilon \\in [-0.01,\\,+0.01]$), we solve for $C_{ij}$. \n",
    "\n",
    "### Using MACE in Practice\n",
    "\n",
    "[MACE](https://github.com/ACEsuit/mace) is a **machine-learned interatomic potential** trained on quantum-mechanical data. It can compute **forces**, **stresses**, and **energies** for a given atomic configuration.\n",
    "\n",
    "1. **Attach the MACE Calculator**  \n",
    "   ```python\n",
    "   calculator = MACECalculator(\n",
    "       model_path=\"MACE-matpes-r2scan-omat-ft.model\",\n",
    "       device=device.type\n",
    "   )\n",
    "   atoms_ref.calc = calculator\n",
    "   ```\n",
    "   This tells the `ase.Atoms` object to use MACE for its energy and force evaluations.\n",
    "\n",
    "2. **Apply Small Strains**  \n",
    "   - We define a helper function `apply_strain(atoms, strain_tensor)` that modifies the cell dimensions according to $\\boldsymbol{\\varepsilon}$.  \n",
    "   - A loop is used to vary $\\varepsilon$ from negative to positive (e.g., $-1\\%$ to $+1\\%$).\n",
    "\n",
    "3. **Compute the Energy**  \n",
    "   - For each strained geometry, MACE calculates the total potential energy:\n",
    "     ```python\n",
    "     energy = atoms_def.get_potential_energy()\n",
    "     ```\n",
    "   - We record these energies in an array, subtract the reference (unstrained) energy to get $\\Delta E(\\varepsilon)$.\n",
    "\n",
    "4. **Extract $ C_{ij} $**  \n",
    "   - Fit $\\Delta E(\\varepsilon)$ vs. $\\varepsilon^2$ using a simple linear regression (or polynomial fit) to solve:\n",
    "     $$\n",
    "       \\Delta E(\\varepsilon) \\;=\\; a\\, \\varepsilon^2 + b\\,\\varepsilon + c\n",
    "     $$\n",
    "     Typically, $b$ and $c$ should be near zero for purely elastic (symmetric) strains, and $a = \\tfrac{1}{2}\\,C_{ij}\\,V$.  \n",
    "   - Rearrange to find $C_{ij}$:\n",
    "     $$\n",
    "       C_{ij} \\;=\\; \\frac{2\\,a}{V}.\n",
    "     $$\n",
    "\n",
    "5. **Interpretation**  \n",
    "   - Repeating for different strain “modes” (e.g., $\\varepsilon_{11}, \\varepsilon_{22}, \\ldots$, or shear strains) lets us extract various diagonal (and sometimes off-diagonal) **elastic constants**.  \n",
    "   - These computed values can be **compared** directly to the model predictions (from the neural network) or **literature** data.\n",
    "\n",
    "This approach leverages MACE’s **ab initio–level accuracy** (learned from high-fidelity quantum-mechanical calculations) but at significantly lower computational cost than running a full DFT simulation for each strain configuration. The result is a **fast and flexible** way to obtain elastic constants by **direct energy or stress evaluations**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BAeRpeWa4OnW"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/ACEsuit/mace-foundations/releases/download/mace_matpes_0/MACE-matpes-r2scan-omat-ft.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hSrviBPV4O_P",
    "outputId": "c67f24b9-31f4-4bfa-ff48-950e288553ef"
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from ase import Atoms\n",
    "from ase.io import read\n",
    "from ase.units import GPa\n",
    "from mace.calculators import MACECalculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X87Nu784sq0"
   },
   "outputs": [],
   "source": [
    "def apply_strain(atoms: Atoms, strain_tensor):\n",
    "    atoms = atoms.copy()\n",
    "    cell = atoms.get_cell()\n",
    "    strain_matrix = np.eye(3) + strain_tensor\n",
    "    atoms.set_cell(np.dot(strain_matrix, cell), scale_atoms=True)\n",
    "    return atoms\n",
    "\n",
    "\n",
    "def compute_elastic_constant(strain_energies, strains, volume):\n",
    "    # Fit E = 0.5 * C * strain^2 → C = 2 * dE/d(strain^2)\n",
    "    coeffs = np.polyfit(strains**2, strain_energies, 1)\n",
    "    return (2 * coeffs[0]) / volume / GPa  # in GPa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jTr2E8cW4wm9",
    "outputId": "1498b72b-915f-40bd-d62b-53c98b8109e9"
   },
   "outputs": [],
   "source": [
    "# Load structure\n",
    "atoms_ref = read(\"Si.cif\")\n",
    "volume = atoms_ref.get_volume()\n",
    "\n",
    "# Attach MACE-MP0 calculator\n",
    "calculator = MACECalculator(\n",
    "    model_path=\"MACE-matpes-r2scan-omat-ft.model\", device=device.type\n",
    ")\n",
    "atoms_ref.calc = calculator\n",
    "\n",
    "# Small strains to apply\n",
    "strain_values = np.linspace(-0.01, 0.01, 11)\n",
    "\n",
    "# Tensor components to compute\n",
    "component_labels = [\"C11\", \"C22\", \"C33\", \"C44\", \"C55\", \"C66\"]\n",
    "strain_tensors = {\n",
    "    \"C11\": lambda e: np.array([[e, 0, 0], [0, 0, 0], [0, 0, 0]]),\n",
    "    \"C22\": lambda e: np.array([[0, 0, 0], [0, e, 0], [0, 0, 0]]),\n",
    "    \"C33\": lambda e: np.array([[0, 0, 0], [0, 0, 0], [0, 0, e]]),\n",
    "    \"C44\": lambda e: np.array([[0, e / 2, 0], [e / 2, 0, 0], [0, 0, 0]]),\n",
    "    \"C55\": lambda e: np.array([[0, 0, e / 2], [0, 0, 0], [e / 2, 0, 0]]),\n",
    "    \"C66\": lambda e: np.array([[0, 0, 0], [0, 0, e / 2], [0, e / 2, 0]]),\n",
    "}\n",
    "\n",
    "elastic_constants = {}\n",
    "all_atoms_def = [atoms_ref.copy()]\n",
    "for label in component_labels:\n",
    "    energies = []\n",
    "    for strain in strain_values:\n",
    "        atoms_def = apply_strain(atoms_ref, strain_tensors[label](strain))\n",
    "        atoms_def.calc = calculator\n",
    "        energy = atoms_def.get_potential_energy()\n",
    "        energies.append(energy)\n",
    "        all_atoms_def.append(atoms_def.copy())\n",
    "    energies = np.array(energies)\n",
    "    strains = np.array(strain_values)\n",
    "    dE = energies - energies[strains == 0][0]\n",
    "    Cij = compute_elastic_constant(dE, strains, volume)\n",
    "    plt.plot(dE, strains)\n",
    "    plt.ylabel(r\"$\\Delta E$ (eV)\")\n",
    "    plt.xlabel(rf\"$\\epsilon_{{{label[1:]}}}$ (-)\")\n",
    "    plt.show()\n",
    "    elastic_constants[label] = Cij\n",
    "    print(f\"{label}: {Cij:.2f} GPa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, Cij in elastic_constants:\n",
    "    print(f\"{label}: {Cij:.2f} GPa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.visualize import view\n",
    "\n",
    "view(all_atoms_def, viewer=\"ngl\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv_scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0a727c1c459149c494105b9f2651a71a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22ae0650f20d40e785d77159c8216a8a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "678ed4d020954b468aeb8d4ecac4beb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71ab7182332b46999d3ba462580ec484": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7edab629f5c3408e8f70b8b2189c9aff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_71ab7182332b46999d3ba462580ec484",
      "max": 13283,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8bed01f2e95544a9b8725124ba2fe7b6",
      "value": 13283
     }
    },
    "8bed01f2e95544a9b8725124ba2fe7b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a26b5014bc7c4654837dc36cc878262b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b9a61170f89c46b7ac59027284efa9c6",
       "IPY_MODEL_7edab629f5c3408e8f70b8b2189c9aff",
       "IPY_MODEL_fc8b52d4632f46d69e3a13f02bbe50fd"
      ],
      "layout": "IPY_MODEL_cacbf547572a48fda76b137c3cac062b"
     }
    },
    "b9a61170f89c46b7ac59027284efa9c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0a727c1c459149c494105b9f2651a71a",
      "placeholder": "​",
      "style": "IPY_MODEL_ee85af6b3dce4bd88545f934770614d9",
      "value": "Retrieving ElasticityDoc documents: 100%"
     }
    },
    "cacbf547572a48fda76b137c3cac062b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee85af6b3dce4bd88545f934770614d9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc8b52d4632f46d69e3a13f02bbe50fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22ae0650f20d40e785d77159c8216a8a",
      "placeholder": "​",
      "style": "IPY_MODEL_678ed4d020954b468aeb8d4ecac4beb6",
      "value": " 13283/13283 [01:05&lt;00:00, 84.67it/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
